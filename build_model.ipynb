{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from random import shuffle\n",
    "from os import listdir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = \"imgs/tweeked/\"\n",
    "file_list = listdir(img_dir)\n",
    "labels = ([filename.split(\"_\")[0] for filename in file_list])\n",
    "\n",
    "classnames, labels = np.unique(labels, return_inverse=True)\n",
    "\n",
    "images =([plt.imread(img_dir+filename)[:,:,:3] for filename in file_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 600, 3)\n"
     ]
    }
   ],
   "source": [
    "image_shape = np.shape(images[1])\n",
    "print(image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "#config = tf.ConfigProto(\n",
    "#        device_count = {'GPU': 0}\n",
    "#    )\n",
    "#sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = list(range(0,len(images)))\n",
    "\n",
    "shuffle(idx)\n",
    "divider = int(3*len(images)/4)\n",
    "train_idx = [idx[i] for i in list(range(0, divider)) ]\n",
    "test_idx = [idx[i] for i in list(range(divider+1, len(images)-1)) ]\n",
    "\n",
    "images_train = np.asarray([images[i] for i in train_idx])\n",
    "images_test = np.asarray([images[i] for i in test_idx])\n",
    "\n",
    "labels_train = np.asarray([labels[i] for i in train_idx])\n",
    "labels_test = np.asarray([labels[i] for i in test_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 596, 596, 10)      760       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 298, 298, 10)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 294, 294, 10)      2510      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 147, 147, 10)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 143, 143, 10)      2510      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 204490)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                13087424  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 13,093,464\n",
      "Trainable params: 13,093,464\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(10, (5, 5), activation='relu', input_shape=image_shape))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(10, (5, 5), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(10, (5, 5), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(4, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 504 samples, validate on 166 samples\n",
      "Epoch 1/15\n",
      "504/504 [==============================] - 64s 127ms/sample - loss: 1.1966 - acc: 0.6468 - val_loss: 0.3049 - val_acc: 0.8916\n",
      "Epoch 2/15\n",
      "504/504 [==============================] - 66s 132ms/sample - loss: 0.3286 - acc: 0.8770 - val_loss: 0.1295 - val_acc: 0.9458\n",
      "Epoch 3/15\n",
      "504/504 [==============================] - 67s 133ms/sample - loss: 0.1547 - acc: 0.9345 - val_loss: 0.0703 - val_acc: 0.9819\n",
      "Epoch 4/15\n",
      "504/504 [==============================] - 64s 126ms/sample - loss: 0.0798 - acc: 0.9583 - val_loss: 0.0679 - val_acc: 0.9759\n",
      "Epoch 5/15\n",
      "504/504 [==============================] - 67s 133ms/sample - loss: 0.0634 - acc: 0.9722 - val_loss: 0.0867 - val_acc: 0.9819\n",
      "Epoch 6/15\n",
      "504/504 [==============================] - 67s 133ms/sample - loss: 0.0622 - acc: 0.9742 - val_loss: 0.0461 - val_acc: 0.9940\n",
      "Epoch 7/15\n",
      "504/504 [==============================] - 68s 134ms/sample - loss: 0.0576 - acc: 0.9782 - val_loss: 0.0717 - val_acc: 0.9759\n",
      "Epoch 8/15\n",
      "504/504 [==============================] - 70s 140ms/sample - loss: 0.0428 - acc: 0.9861 - val_loss: 0.0216 - val_acc: 1.0000\n",
      "Epoch 9/15\n",
      "504/504 [==============================] - 70s 140ms/sample - loss: 0.0664 - acc: 0.9683 - val_loss: 0.1523 - val_acc: 0.9639\n",
      "Epoch 10/15\n",
      "504/504 [==============================] - 68s 135ms/sample - loss: 0.0674 - acc: 0.9782 - val_loss: 0.0418 - val_acc: 0.9819\n",
      "Epoch 11/15\n",
      "504/504 [==============================] - 67s 133ms/sample - loss: 0.0539 - acc: 0.9782 - val_loss: 0.1191 - val_acc: 0.9578\n",
      "Epoch 12/15\n",
      "504/504 [==============================] - 67s 132ms/sample - loss: 0.1289 - acc: 0.9544 - val_loss: 0.1673 - val_acc: 0.9578\n",
      "Epoch 13/15\n",
      "504/504 [==============================] - 65s 129ms/sample - loss: 0.0643 - acc: 0.9802 - val_loss: 0.0232 - val_acc: 0.9819\n",
      "Epoch 14/15\n",
      "504/504 [==============================] - 65s 130ms/sample - loss: 0.0153 - acc: 0.9980 - val_loss: 0.0137 - val_acc: 1.0000\n",
      "Epoch 15/15\n",
      "504/504 [==============================] - 66s 131ms/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0109 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(images_train, labels_train, epochs=15, \n",
    "                    validation_data=(images_test, labels_test)),"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
